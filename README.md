# ShipEngine API Test Project

Test assignment for developing CRUD methods for ShipEngine API endpoints using FastAPI, SQLAlchemy, PostgreSQL, and asynchronous technologies.

## ğŸ“‹ Project Description

Simplified API implementation for addresses, warehouses, and shipments based on [ShipEngine OpenAPI](https://shipengine.github.io/shipengine-openapi/). Complete end-to-end request processing: from endpoint to database write/read operations.

## ğŸ—ï¸ Architecture

Based on [FastAPI-boilerplate](https://benavlabs.github.io/FastAPI-boilerplate/) from Benav Labs. Architecture was barely modified as the standard structure is adequate for the tasks.

**Service Layer** (`src/app/services/`) â€” the only significant addition. Handles:
- Creating/updating entities with relationships (addresses, warehouses, shipments)
- Transaction management for multiple related entities
- Business logic beyond simple CRUD operations

```
src/app/
â”œâ”€â”€ api/v1/          # API endpoints
â”œâ”€â”€ services/         # Business logic (added)
â”œâ”€â”€ crud/             # CRUD operations (FastCRUD)
â”œâ”€â”€ models/           # SQLAlchemy models
â”œâ”€â”€ schemas/          # Pydantic schemas
â”œâ”€â”€ core/             # Configuration, DB, utilities
â””â”€â”€ middleware/       # Logging, caching
```

## ğŸ“¦ Entities

Three main entities from ShipEngine API:

1. **Address** â€” base entity for address information
2. **Warehouse** â€” warehouse with origin/return addresses
3. **Shipment** â€” shipment with warehouse and address references

**Simplifications:**
- Address: simplified structure, no real validation API integration
- Warehouse: basic fields only (name, addresses, default flag)
- Shipment: basic fields, simple status progression logic, no carrier API integration

## ğŸ”§ Technology Stack

**Required:** Python 3.11+, FastAPI, SQLAlchemy 2.0, PostgreSQL, AsyncIO, asyncpg, ARQ

**Additional:** FastCRUD, Pydantic v2, Alembic, Redis, Uvicorn, structlog

## ğŸš€ Functionality

### CRUD Operations

**Warehouses:** `GET /api/v1/warehouses`, `POST`, `GET /{id}`, `PUT /{id}`, `DELETE /{id}`

**Shipments:** `GET /api/v1/shipments` (paginated), `POST`, `GET /{id}`, `PUT /{id}`, `DELETE /{id}`, `POST /{id}/update-tracking`

All create/update operations use transactions (`async with db.begin()`) for data integrity.

### Background Tasks (ARQ Worker)

Worker `update_shipment_tracking_status` implements status progression: `PENDING â†’ PROCESSING â†’ SHIPPED â†’ IN_TRANSIT â†’ DELIVERED`. Auto-schedules next update in 5 minutes (unless terminal status: `DELIVERED`, `CANCELLED`, `FAILED`).

**Note:** Worker implemented solely to demonstrate ARQ usage. In a real project, endpoints are simple enough and don't require background processing.

## ğŸ§ª Testing

Tests cover:
- API endpoint `update_shipment_tracking` (success, errors, queue handling)
- Worker `update_shipment_tracking_status` (status progression, terminal states, error handling)

Run: `pytest tests/`

## ğŸ”„ Data Flow

```
API Layer â†’ Service Layer â†’ CRUD Layer â†’ Model Layer â†’ Response
```

Example: `POST /api/v1/shipments` â†’ validates warehouse â†’ creates addresses â†’ creates shipment (all in transaction) â†’ enqueues background job

## ğŸ“Š Database

**Schema:**
- `address` (id, name, email, phone, address fields, country_code, timestamps)
- `warehouse` (id, name, is_default, origin_address_id, return_address_id, timestamps)
- `shipment` (id, warehouse_id, ship_to_id, ship_from_id, carrier, service_code, tracking_number, status, timestamps)

**Migrations:** `cd src && uv run alembic revision --autogenerate && uv run alembic upgrade head`

## ğŸš§ Production Requirements

1. **Rate Limiting** â€” connect existing infrastructure to endpoints
2. **Security/Authorization** â€” add JWT authentication, protect endpoints
3. **Tests** â€” integration tests, transaction tests, business logic tests, API tests
4. **Improvements** â€” address validation API, better error handling, structured logging, monitoring

## ğŸƒ Running

**Requirements:** Python 3.11+, PostgreSQL, Redis

**Local:**
```bash
uv sync
cp scripts/local_with_uvicorn/.env.example src/.env
docker compose up -d postgres redis
cd src && uv run alembic upgrade head
uv run uvicorn src.app.main:app --reload
# In separate terminal:
cd src && uv run python -m app.core.worker.settings
```

**Docker:** `docker compose up`

App: `http://localhost:8000`, Docs: `http://localhost:8000/docs`

## ğŸ“š Resources

- [FastAPI Boilerplate Guide](https://benavlabs.github.io/FastAPI-boilerplate/user-guide/)
- [ShipEngine OpenAPI](https://shipengine.github.io/shipengine-openapi/)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [SQLAlchemy 2.0](https://docs.sqlalchemy.org/en/20/)
- [ARQ Docs](https://arq-docs.helpmanual.io/)

## ğŸ“„ License

MIT
